{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackgroundPath = r'Resources\\background.png'  # Use a raw string\n",
    "imgBackground = cv2.imread(imgBackgroundPath)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        if imgBackground is not None:\n",
    "            imgBackground[162:162 + 480, 55:55 + 640] = frame\n",
    "            cv2.imshow(\"Background Image\", imgBackground)\n",
    "        else:\n",
    "            cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use a regular string literal like 'Resources\\background.png', Python interprets the '\\b' as a backspace character, not as part of the path. This can lead to incorrect paths and errors when attempting to read or write files.\n",
    "\n",
    "By using a raw string literal (r'Resources\\background.png'), you indicate to Python that backslashes should be treated as literal characters and not as escape characters. This ensures that the path is interpreted correctly, especially in contexts like file paths on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cvzone\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "\n",
    "# Loading the encoding file\n",
    "print(\"Loading Encode File ...\")\n",
    "file = open('EncodeFile.p', 'rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown, studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "imgBackgroundPath = r'Resources\\background.png'  # Use a raw string \n",
    "imgBackground = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "imgBackground = cv2.imread(imgBackgroundPath)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame from the video source\")\n",
    "        break  # exit the loop or handle the error accordingly\n",
    "    \n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[1]\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        print(\"matches\",matches)\n",
    "        print(\"faceDis\",faceDis)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Break the loop if 'q' is pressed\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above code is to check whether the face recognition process is working well. The id that shows true is matching with the frame and it has least faceDis among all other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cvzone\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "\n",
    "# Loading the encoding file\n",
    "print(\"Loading Encode File ...\")\n",
    "file = open('EncodeFile.p', 'rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown, studentIds = encodeListKnownWithIds\n",
    "print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "imgBackgroundPath = r'Resources\\background.png'  # Use a raw string \n",
    "imgBackground = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "imgBackground = cv2.imread(imgBackgroundPath)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Error reading frame from the video source\")\n",
    "        break  # exit the loop or handle the error accordingly\n",
    "    \n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[1]\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        \n",
    "        matchIndex = np.argmin(faceDis)\n",
    "        if matches[matchIndex]:\n",
    "            # print(\"Known Face Detected\")\n",
    "            # print(studentIds[matchIndex])\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "            imgBackground = cvzone.cornerRect(imgBackground, bbox, rt=0)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Break the loop if 'q' is pressed\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code generates a square around a known detected face i.e. face which is there in our encodings"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
